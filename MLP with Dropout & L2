
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import tensorflow as tf
import matplotlib.pyplot as plt

# Load the data
pre = np.nan_to_num(np.load("C:/Users/zheng/OneDrive/Desktop/Bachelor/F0254/events_pre.npy"))
post = np.nan_to_num(np.load("C:/Users/zheng/OneDrive/Desktop/Bachelor/F0254/events_post.npy"))

# Flatten the data for classification
pre_flat = pre.reshape(pre.shape[0], -1)
post_flat = post.reshape(post.shape[0], -1)

# Create labels: pre = 1, post = 0
labels_pre = np.ones(pre_flat.shape[0])
labels_post = np.zeros(post_flat.shape[0])

# Combine data and labels
data = np.concatenate([pre_flat, post_flat], axis=0)
labels = np.concatenate([labels_pre, labels_post], axis=0)

# Split the data into training (80%) and testing (20%) sets
data_train, data_test, labels_train, labels_test = train_test_split(
    data, labels, test_size=0.2, random_state=42
)

# Normalize the data
scaler = StandardScaler()
data_train = scaler.fit_transform(data_train)
data_test = scaler.transform(data_test)

# Define the Multi-Layer Perceptron (MLP) model with regularization and dropout
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(data_train.shape[1],),
                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.Dropout(0.5),  # Drop 50% of neurons during training
    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.Dropout(0.5),  # Drop another 50%
    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(
    data_train, labels_train,
    validation_split=0.2,
    epochs=30,
    batch_size=32,
    verbose=1
)

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(data_test, labels_test, verbose=0)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Generate predictions for the test set
labels_pred = (model.predict(data_test) > 0.5).astype(int)

# Classification report
print("\nClassification Report:")
print(classification_report(labels_test, labels_pred))

# Confusion matrix
cm = confusion_matrix(labels_test, labels_pred)
print("\nConfusion Matrix:")
print(cm)

# Plot training history
plt.figure(figsize=(12, 6))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()
